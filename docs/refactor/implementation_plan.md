# Broker & Bifrost Refactor - Implementation Plan

**Date**: 2025-10-12
**Status**: üîÑ In Progress - Phase 2
**Estimated Time**: 11-15 hours
**Work Location**: `/Users/chiraagbalu/research/broker/` and `/Users/chiraagbalu/research/bifrost/`

---

## Pre-Implementation Verification (2025-10-12)

### ‚úÖ Infrastructure Check
- **Shared logging**: EXISTS at `/Users/chiraagbalu/llm-workbench/shared/`
  - ‚úÖ `logging_config.py` - Logger setup utilities
  - ‚úÖ `json_formatter.py` - JSON log formatting
  - ‚úÖ `ssh_foundation.py` - Base SSH client utilities
  - ‚úÖ `logging.md` - Documentation

### ‚úÖ Current Codebase Size
- **Total LOC**: ~6,752 lines (broker + bifrost main modules)
- **Broker**: `/Users/chiraagbalu/llm-workbench/broker/broker/` (15+ files)
- **Bifrost**: `/Users/chiraagbalu/llm-workbench/bifrost/bifrost/` (11+ files)

### ‚úÖ Architecture Clarifications Confirmed
1. **Broker Provider Flow**: GPUClient ‚Üí Provider(api_key) ‚Üí Instance(provider=self) ‚Üí wait methods use provider's api_key
2. **Bifrost Pure Functions**: No GitDeployment class, pure functions in git_sync.py with RemoteConfig dataclass
3. **Bootstrap Timeout**: Python parameter (not env var) in `run_detached(bootstrap_timeout=600)`
4. **Multi-Provider**: Implement both RunPod + Vast (Vast raises NotImplementedError initially)

### ‚ö†Ô∏è Bootstrap Timeout Implementation Detail
**DECISION NEEDED**: Line 797 shows env var `BOOTSTRAP_TIMEOUT=${BOOTSTRAP_TIMEOUT:-600}` but clarification says make it Python parameter.
**SOLUTION**: Pass `bootstrap_timeout` parameter through to shell script:
```python
def run_detached(self, command: str, bootstrap_cmd: Optional[str] = None,
                 bootstrap_timeout: int = 600, ...) -> JobInfo:
    # Pass timeout to shell script
    command_script = f"BOOTSTRAP_TIMEOUT={bootstrap_timeout} && ..."
```

---

## Project Paths

**Current Implementation:**
- Broker: `/Users/chiraagbalu/llm-workbench/broker/broker/`
- Bifrost: `/Users/chiraagbalu/llm-workbench/bifrost/bifrost/`
- Shared logging: `/Users/chiraagbalu/llm-workbench/shared/`

**Git Strategy:**
- Work directly on `main` branch
- No feature branch needed (author's personal tool)
- Tag before starting: `git tag before-refactor-2025-10-12`

**Test Strategy:**
- Break all tests immediately - no incremental compatibility
- Rewrite/fix tests at end (Phase 4)
- Move fast, fix what breaks

**Multi-Provider:**
- Currently only RunPod provider implemented
- Multi-provider architecture is future work
- Design for extensibility, implement single provider first

---

## Key Architecture Changes (Final)

### Broker: Provider Flow for API Keys
```python
# Client initializes providers with credentials
client = GPUClient(credentials={"runpod": "key1"}, ssh_key_path="~/.ssh/id_ed25519")
# ‚Üí Creates RunPodProvider(api_key="key1") internally

# Provider creates instances and injects itself
instance = provider.create_instance(offer)
# ‚Üí Returns GPUInstance(provider=self, ...)

# Instance wait methods use provider's api_key
instance.wait_until_ssh_ready()
# ‚Üí Calls self.provider.get_instance_details(self.id)
# ‚Üí Provider uses its self.api_key internally
```

### Bifrost: Pure Functions + RemoteConfig
```python
# BifrostClient stores RemoteConfig (not class state)
client = BifrostClient(ssh_connection="root@1.2.3.4:22", ssh_key_path="~/.ssh/id_ed25519")
# ‚Üí Creates RemoteConfig(host="1.2.3.4", port=22, user="root", key_path="...")

# Pure functions in git_sync.py (no GitDeployment class)
workspace = deploy_code(ssh_client, remote_config, "~/.bifrost/workspace")
install_dependencies(ssh_client, remote_config, workspace, "uv sync")
# ‚Üí Stateless functions, easy to test
```

---

## Clarifications from Review (2025-10-12)

### Multi-Provider Architecture (Future Work)
- ‚úÖ Design for multiple providers (RunPod, Vast, Lambda, etc.)
- ‚úÖ Provider filter as part of DSL: `client.provider.in_(['runpod', 'vast'])`
- ‚úÖ Credentials as dict: `{"runpod": "key1", "vast": "key2"}`
- ‚úÖ GPUInstance/GPUOffer know their provider via `provider_name` field
- ‚úÖ Search results returned unsorted (user controls sorting)
- ‚ö†Ô∏è Only RunPod implemented initially - architecture ready for others

### SSH Key Validation (Tiger Style)
- ‚úÖ Assert file exists and is readable
- ‚úÖ Warn (don't fail) on insecure permissions (not 0600)
- ‚úÖ Assert reasonable file size (<10KB)
- ‚úÖ Let SSH library validate key format (don't parse ourselves)

### API Key Access in Wait Methods
- ‚úÖ Use ClientGPUInstance wrapper (Option D)
- ‚úÖ GPUInstance data class stays pure (no api_key field)
- ‚úÖ GPUInstance has `provider: GPUProvider` field (provider already has api_key)
- ‚úÖ Provider flow:
  1. `GPUClient.__init__()` creates `RunPodProvider(api_key="...")`
  2. `provider.create_instance(offer)` returns `GPUInstance(provider=self, ...)`
  3. `instance.wait_until_ssh_ready()` calls `self.provider.get_instance_details(self.id)`
  4. Provider uses its stored `self.api_key` internally

### Workspace Design Constraints
- ‚úÖ Assume one project per GPU instance (no multi-project support)
- ‚úÖ Single shared workspace at `~/.bifrost/workspace`
- ‚úÖ Document this constraint clearly (can relax later if needed)

### Bootstrap Session Coordination
- ‚úÖ Configurable timeout (default 10 minutes)
- ‚úÖ Check if tmux session alive during wait
- ‚úÖ Manual cleanup/restart (no automatic retry)
- ‚úÖ Simple design with known edge cases

### Logging Strategy
- ‚úÖ Use existing shared/logging infrastructure from repo
- ‚úÖ User configures logging (library doesn't set it up)
- ‚úÖ Standard levels: DEBUG/INFO/WARNING/ERROR

### Error Handling in exec()
- ‚úÖ Return ExecResult dataclass (stdout, stderr, exit_code)
- ‚úÖ Never raise on non-zero exit (user decides)
- ‚úÖ Provides `.success` property for convenience

### Environment Variables
- ‚úÖ Use `shlex.quote()` for safety (no size limits)
- ‚úÖ Trust battle-tested stdlib (don't over-engineer)

### Assertion Strategy (Tiger Style)
- ‚úÖ Minimum 2 assertions per function
- ‚úÖ Assert all function inputs, outputs, and invariants
- ‚úÖ Pair assertions at boundaries (before write, after read)
- ‚úÖ Use assertions for programmer errors (fail fast)
- ‚úÖ Use try/catch only at external boundaries (network, filesystem, user input)
- ‚úÖ Focus on cost-critical paths (provider operations, instance creation)
- ‚úÖ Document assumptions through assertions

**Philosophy:**
- Assertions catch bugs during development, not production
- Better to crash immediately than corrupt state
- Assertions are self-documenting code
- Try/catch is for expected errors, assertions are for impossible states

### Additional Clarifications

**Testing Strategy (Q9):**
- ‚úÖ All-or-nothing approach: fuck it we ball
- ‚úÖ No test compatibility during refactor
- ‚úÖ Rewrite tests after seeing what breaks
- ‚úÖ Move fast, fix issues as they arise

**Backward Compatibility (Q10):**
- ‚úÖ Clean break, no v1 support after v2 ships
- ‚úÖ This is primarily author's tool, not public library
- ‚úÖ No deprecation period needed

**Rollback Strategy (Q11):**
- ‚úÖ Push through - no partial shipping
- ‚úÖ Complete all 4 phases or revert entirely
- ‚úÖ Work directly on main branch
- ‚úÖ Use git tags for safety: `git tag before-refactor-2025-10-12`

**Provider & Circular Imports (Q12):**
- ‚úÖ Wait methods stay on GPUInstance
- ‚úÖ GPUInstance has `provider: GPUProvider` field
- ‚úÖ Provider creates instances and injects itself
- ‚úÖ Provider initialized with api_key from client credentials
- ‚úÖ Provider stores api_key internally, used by all provider methods
- ‚úÖ Flow: Client ‚Üí Provider(api_key) ‚Üí Instance(provider=self)
- ‚úÖ No circular imports: types.py ‚Üí providers.base, providers.runpod ‚Üí types.py

**Job ID Collisions (Q13):**
- ‚úÖ Add random suffix using `secrets.token_hex(4)`
- ‚úÖ Format: `{name}-{timestamp}-{random}` (e.g., `training-20251012-143025-a3f2b8c1`)
- ‚úÖ ~4 billion combinations, effectively zero collision risk

**Git Deployment Methods (Q14):**
- ‚úÖ Pure functions in git_sync.py (No classes, just functions)
- ‚úÖ `deploy_code(ssh_client, remote_config, workspace)` - stateless
- ‚úÖ `install_dependencies(ssh_client, remote_config, workspace, cmd)` - stateless
- ‚úÖ RemoteConfig dataclass for SSH connection info (host, port, user, key_path)
- ‚úÖ BifrostClient orchestrates, no GitDeployment class

**Casey's Granularity (Q15):**
- ‚úÖ Current 3-method API is right balance
- ‚úÖ push/exec/deploy provides composability
- ‚úÖ Coupling push+bootstrap makes sense (idempotent uv sync)

**Sean's Minimize State (Q16):**
- ‚úÖ Flag files are acceptable operational state
- ‚úÖ Ephemeral coordination, not application state
- ‚úÖ Timeout handles edge cases, simple and debuggable

**Tiger Style Assertions (Q17):**
- ‚úÖ Aggressive assertion strategy everywhere
- ‚úÖ Especially cost-critical paths (provider ops, instance creation)
- ‚úÖ Assertions are cheap, catch bugs early
- ‚úÖ Prefer fail-fast over defensive programming

## Final Decisions Summary

### Architecture Decisions
- ‚úÖ Keep ClientGPUInstance wrapper (convenience worth coupling)
- ‚úÖ Keep wait methods on instance (clean up implementation)
- ‚úÖ Provider registry: Multi-provider with DSL filtering
- ‚úÖ SSH key: Required parameter with validation (no auto-discovery)
- ‚úÖ Streaming: Callback-based (current implementation)
- ‚úÖ Bootstrap: Separate tmux sessions with timeout
- ‚úÖ Docker: Document as future feature, skip for now

### Code to Remove
- ‚ùå `validate_configuration()` - useless theater
- ‚ùå `get_proxy_url/urls()` - provider leakage
- ‚ùå Print statements in wait methods
- ‚ùå SSH auto-discovery logic
- ‚ùå Circular imports (types.py ‚Üí api.py)
- ‚ùå 5 redundant deploy methods
- ‚ùå Deprecated `run()` method
- ‚ùå Auto-bootstrap detection
- ‚ùå Complex stdin env injection
- ‚ùå Worktree (keep workspace only)

### Code to Keep/Enhance
- ‚úÖ ClientGPUInstance wrapper
- ‚úÖ Wait methods (replace prints with logging)
- ‚úÖ Provider registry (for extensibility)
- ‚úÖ Streaming exec (callback-based)
- ‚úÖ 3 bifrost methods: push(), exec(), deploy()

---

## Target Metrics

| Metric | Before | After | Reduction |
|--------|--------|-------|-----------|
| **Broker LOC** | 5,200 | ~1,200 | 77% |
| **Bifrost LOC** | 3,500 | ~1,000 | 71% |
| **Broker API methods** | 40 | 15 | 63% |
| **Bifrost API methods** | 35 | 13 | 63% |
| **Total LOC** | 8,700 | ~2,200 | 75% |

---

## Implementation Phases

### Phase 1: Cleanup & Remove Bloat (2-3 hours)

**Goal**: Remove dead code and simplify without breaking functionality

#### 1.1 Remove Deprecated/Useless Methods

**Broker** - Remove from `client.py`:
```python
# DELETE THIS (lines 116-144)
def validate_configuration(self) -> Dict[str, str]:
    """Validate configuration and return status report"""
    # ... 28 lines of emoji theater
```

**Broker** - Remove from `types.py`:
```python
# DELETE THIS (lines 291-352)
def get_proxy_url(self, port: int) -> Optional[str]:
    """Get RunPod HTTP proxy URL for a specific port."""
    # ... RunPod-specific leakage

def get_proxy_urls(self, ports: Optional[List[int]] = None) -> Dict[int, str]:
    """Get RunPod HTTP proxy URLs for exposed ports."""
    # ... provider-specific
```

**Bifrost** - Remove from `client.py`:
```python
# DELETE THIS (lines 276-306)
def run(self, command: str, env: Optional[Dict[str, str]] = None, no_deploy: bool = False) -> str:
    """DEPRECATED: Use deploy() instead."""
    # ... 31 lines
```

**Bifrost** - Remove deprecated parameter from `exec()`:
```python
# BEFORE
def exec(self, command: str, env: Optional[Dict[str, str]] = None,
         working_dir: Optional[str] = None, worktree: Optional[str] = None) -> str:
    # Handle deprecated worktree parameter
    if worktree is not None:
        warnings.warn(...)

# AFTER
def exec(self, command: str, env: Optional[Dict[str, str]] = None,
         working_dir: Optional[str] = None) -> str:
    # Clean implementation
```

#### 1.2 Remove SSH Auto-Discovery

**Broker** - `client.py`:
```python
# BEFORE
def __init__(self, ssh_key_path: Optional[str] = None, api_key: Optional[str] = None):
    if ssh_key_path:
        self.set_ssh_key_path(ssh_key_path)
    else:
        self._discover_ssh_key()  # DELETE THIS METHOD

# AFTER
def __init__(self, credentials: Dict[str, str], ssh_key_path: str):
    """Initialize GPU broker client

    Args:
        credentials: Dict mapping provider name to API key
                    e.g., {"runpod": "key1", "vast": "key2"}
        ssh_key_path: Path to SSH private key (required)
    """
    # Assert inputs
    assert isinstance(credentials, dict), "credentials must be dict"
    assert len(credentials) > 0, "credentials dict cannot be empty"
    for provider_name, api_key in credentials.items():
        assert isinstance(provider_name, str), f"Provider name must be string: {provider_name}"
        assert isinstance(api_key, str), f"API key must be string for {provider_name}"
        assert len(api_key) > 0, f"API key cannot be empty for {provider_name}"

    assert isinstance(ssh_key_path, str), "ssh_key_path must be string"
    assert len(ssh_key_path) > 0, "ssh_key_path cannot be empty"

    self._credentials = credentials
    self._ssh_key_path = os.path.expanduser(ssh_key_path)

    # Validate SSH key (Tiger Style: assert everything, fail fast)
    assert os.path.exists(self._ssh_key_path), \
        f"SSH private key not found: {self._ssh_key_path}"

    assert os.access(self._ssh_key_path, os.R_OK), \
        f"SSH private key not readable: {self._ssh_key_path}"

    # Warn on bad permissions (non-blocking)
    stat_info = os.stat(self._ssh_key_path)
    if stat_info.st_mode & 0o077:
        logger.warning(
            f"SSH key has insecure permissions: {oct(stat_info.st_mode)[-3:]}. "
            f"Recommend: chmod 600 {self._ssh_key_path}"
        )

    # Assert reasonable file size
    assert stat_info.st_size < 10_000, \
        f"SSH key file suspiciously large ({stat_info.st_size} bytes): {self._ssh_key_path}"

    self._query = GPUQuery()

    # Assert output invariants
    assert self._credentials, "Failed to set credentials"
    assert self._ssh_key_path, "Failed to set ssh_key_path"
    assert self._query is not None, "Failed to initialize query"

# DELETE ENTIRE METHOD (lines 91-114)
def _discover_ssh_key(self):
    """Auto-discover SSH key from common locations"""
    # ... 24 lines
```

#### 1.3 Clean Up Wait Methods

**Broker** - `types.py`:

```python
# BEFORE (lines 188-289)
def wait_until_ssh_ready(self, timeout: int = 300) -> bool:
    # ... mixed with print statements
    print(f"‚úÖ Direct SSH assigned: {self.public_ip}:{self.ssh_port}")
    # ... circular import
    from .api import get_instance

# AFTER
def wait_until_ssh_ready(self, timeout: int = 300) -> bool:
    """Wait until instance is running AND SSH is ready for connections.

    Uses internally stored API key to poll provider for status.

    Args:
        timeout: Maximum seconds to wait

    Returns:
        True if SSH ready, False if timeout or failure
    """
    import time
    import logging

    logger = logging.getLogger(__name__)
    start_time = time.time()

    # First wait for instance to be running
    if not self.wait_until_ready(timeout=min(timeout, 300)):
        return False

    # Wait for SSH assignment (direct, not proxy)
    logger.info("Waiting for direct SSH to be assigned...")

    while time.time() - start_time < timeout:
        # Get fresh data directly from provider
        # Provider is passed the api_key from wrapper
        fresh = self.provider.get_instance_details(self.id)

        if fresh and fresh.public_ip and fresh.ssh_port:
            if fresh.public_ip != "ssh.runpod.io":
                # Update current instance with fresh data
                self.__dict__.update(fresh.__dict__)
                logger.info(f"Direct SSH assigned: {self.public_ip}:{self.ssh_port}")

                # Wait for SSH daemon to initialize
                logger.info("Waiting 30s for SSH daemon to initialize...")
                time.sleep(30)

                # Test SSH connectivity
                try:
                    result = self.exec("echo 'ssh_ready'", timeout=30)
                    if result.success and "ssh_ready" in result.stdout:
                        logger.info("SSH connectivity confirmed")
                        return True
                    else:
                        logger.warning(f"SSH test failed: {result.stderr}")
                except Exception as e:
                    logger.warning(f"SSH connection error: {e}")

        elapsed = int(time.time() - start_time)
        logger.debug(f"Still waiting for SSH - {elapsed}s elapsed")
        time.sleep(10)

    logger.error(f"Timeout waiting for SSH after {timeout}s")
    return False
```

**Similar cleanup for** `wait_until_ready()` - replace all print() with logger calls.

#### 1.4 Update Examples and Tests

**Update all examples** to use explicit parameters:
```python
# BEFORE
client = GPUClient()  # Auto-discovery

# AFTER
client = GPUClient(
    credentials={
        "runpod": os.environ["RUNPOD_API_KEY"],
        "vast": os.environ.get("VAST_API_KEY", ""),
    },
    ssh_key_path="~/.ssh/id_ed25519"
)

# Search with provider filter
offers = client.search(
    client.provider.in_(['runpod', 'vast']) &
    client.gpu_type.contains("RTX") &
    client.price_per_hour < 0.50
)
```

**Test files to update** (in Phase 4):
- `llm-workbench/broker/tests/test_broker_sync.py`
- `llm-workbench/broker/tests/test_broker_async.py`
- `llm-workbench/broker/tests/test_streaming_ssh_*.py`
- `llm-workbench/broker/examples/*.py`
- `llm-workbench/bifrost/tests/test_bifrost_sync.py`
- `llm-workbench/bifrost/tests/test_bifrost_async.py`

**Note:** Tests will break during Phases 1-3. Fix/rewrite in Phase 4.

---

### Phase 2: Consolidate & Simplify (3-4 hours)

**Goal**: Unify redundant code paths and simplify implementations

#### 2.1 Consolidate Bifrost Deploy Methods

**Current mess** in `deploy.py`:
- `deploy_and_execute()` (line 373)
- `deploy_to_workspace()` (line 399)
- `deploy_code_only()` (line 451)
- `deploy_and_execute_detached()` (line 526)
- `deploy_and_execute_detached_workspace()` (line 594)

**New approach** - Keep only internal helpers:
- `_deploy_code()` - Git sync to workspace
- `_install_dependencies()` - Run bootstrap command
- `_execute_command()` - Run command in workspace

**Delete** all 5 public methods, they're only called from `BifrostClient`.

**In `git_sync.py`**, pure functions:
```python
from typing import Optional
import paramiko
from .types import RemoteConfig

def deploy_code(ssh_client: paramiko.SSHClient,
                config: RemoteConfig,
                workspace_path: str) -> str:
    """Deploy code via git to remote workspace.

    Args:
        ssh_client: Active SSH client connection
        config: Remote connection configuration
        workspace_path: Path to workspace on remote (e.g., ~/.bifrost/workspace)

    Returns:
        Path to deployed workspace
    """
    # Assert inputs
    assert ssh_client is not None, "ssh_client cannot be None"
    assert isinstance(config, RemoteConfig), "config must be RemoteConfig"
    assert isinstance(workspace_path, str) and len(workspace_path) > 0, \
        "workspace_path must be non-empty string"

    # Git sync logic here (simplified for plan)
    # ... check if workspace exists, git pull or clone, etc ...

    # Assert output
    assert workspace_path, "Failed to deploy code"
    return workspace_path

def install_dependencies(ssh_client: paramiko.SSHClient,
                        config: RemoteConfig,
                        workspace_path: str,
                        bootstrap_cmd: str) -> None:
    """Run bootstrap command to install dependencies.

    Args:
        ssh_client: Active SSH client connection
        config: Remote connection configuration
        workspace_path: Path to workspace on remote
        bootstrap_cmd: Command to run (e.g., "uv sync --frozen")
    """
    # Assert inputs
    assert ssh_client is not None, "ssh_client cannot be None"
    assert isinstance(config, RemoteConfig), "config must be RemoteConfig"
    assert isinstance(workspace_path, str) and len(workspace_path) > 0, \
        "workspace_path must be non-empty string"
    assert isinstance(bootstrap_cmd, str) and len(bootstrap_cmd) > 0, \
        "bootstrap_cmd must be non-empty string"

    # Run bootstrap command
    # ... execute bootstrap_cmd in workspace_path ...
```

**In `client.py`**, methods become:
```python
from .git_sync import deploy_code, install_dependencies

def __init__(self, ssh_connection: str, ssh_key_path: str):
    """Initialize Bifrost client.

    Args:
        ssh_connection: SSH connection string (user@host:port)
        ssh_key_path: Path to SSH private key
    """
    # Parse connection string
    parts = ssh_connection.split('@')
    assert len(parts) == 2, f"Invalid ssh_connection format: {ssh_connection}"
    user = parts[0]

    host_port = parts[1].split(':')
    host = host_port[0]
    port = int(host_port[1]) if len(host_port) > 1 else 22

    # Create remote config
    self._remote_config = RemoteConfig(
        host=host,
        port=port,
        user=user,
        key_path=os.path.expanduser(ssh_key_path)
    )

def push(self, bootstrap_cmd: Optional[str] = None) -> str:
    """Deploy code to remote workspace.

    Args:
        bootstrap_cmd: Explicit command to install dependencies
                      (e.g., "uv sync --frozen")

    Returns:
        Path to deployed workspace
    """
    # Assert input
    if bootstrap_cmd is not None:
        assert isinstance(bootstrap_cmd, str) and len(bootstrap_cmd) > 0, \
            "bootstrap_cmd must be non-empty string"

    ssh_client = self._get_ssh_client()
    workspace_path = "~/.bifrost/workspace"

    # Deploy code (pure function)
    workspace_path = deploy_code(ssh_client, self._remote_config, workspace_path)

    # Install dependencies if specified (pure function)
    if bootstrap_cmd:
        install_dependencies(ssh_client, self._remote_config, workspace_path, bootstrap_cmd)

    # Assert output
    assert workspace_path, "push() returned empty workspace_path"
    return workspace_path

def exec(self, command: str, working_dir: Optional[str] = None,
         env: Optional[Dict[str, str]] = None) -> ExecResult:
    """Execute command in remote workspace.

    Args:
        command: Command to execute
        working_dir: Directory to run in (default: ~/.bifrost/workspace)
        env: Environment variables (exported as VAR=value)

    Returns:
        ExecResult with stdout, stderr, exit_code
    """
    client = self._get_ssh_client()

    # Default to workspace if exists
    if working_dir is None:
        working_dir = "~/.bifrost/workspace"

    # Build command with environment
    full_cmd = self._build_command_with_env(command, working_dir, env)

    # Execute
    stdin, stdout, stderr = client.exec_command(full_cmd)
    exit_code = stdout.channel.recv_exit_status()

    return ExecResult(
        stdout=stdout.read().decode(),
        stderr=stderr.read().decode(),
        exit_code=exit_code
    )

def deploy(self, command: str, bootstrap_cmd: Optional[str] = None,
           env: Optional[Dict[str, str]] = None) -> str:
    """Deploy code and execute command.

    Equivalent to: push(bootstrap_cmd) + exec(command, env)

    Args:
        command: Command to execute
        bootstrap_cmd: Optional dependency installation command
        env: Environment variables

    Returns:
        Command output
    """
    workspace_path = self.push(bootstrap_cmd)
    return self.exec(command, working_dir=workspace_path, env=env)
```

#### 2.2 Simplify Environment Injection

**Current complexity** - `deploy.py` lines 18-117:
- Regex validation
- Stdin piping
- Wrapper generation

**New approach** - Simple exports:
```python
def _build_command_with_env(self, command: str, working_dir: str,
                            env: Optional[Dict[str, str]]) -> str:
    """Build command with environment variables and working directory.

    Args:
        command: Command to execute
        working_dir: Directory to run in
        env: Environment variables

    Returns:
        Full command string with cd and exports
    """
    parts = []

    # Change directory
    parts.append(f"cd {working_dir}")

    # Export environment variables
    if env:
        for key, value in env.items():
            # Basic validation
            if not key.isidentifier():
                raise ValueError(f"Invalid env var name: {key}")
            # Use shell quoting for safety
            import shlex
            parts.append(f"export {key}={shlex.quote(value)}")

    # Execute command
    parts.append(command)

    return " && ".join(parts)
```

**Delete** from `deploy.py`:
- `make_env_payload()` (lines 20-28)
- `wrap_with_env_loader()` (lines 30-36)
- `execute_with_env_injection()` (lines 38-117)

#### 2.3 Remove Auto-Bootstrap Detection

**Delete** from `deploy.py`:
```python
# DELETE THIS (lines 129-160)
def detect_bootstrap_command(self, client, worktree_path, uv_extra):
    """Detect Python dependency files and return appropriate bootstrap command."""
    # ... 32 lines of auto-detection
```

**Callers** must now pass explicit `bootstrap_cmd`:
```python
# BEFORE
deployment.deploy_and_execute(client, command)  # Auto-detects bootstrap

# AFTER
client.deploy(command, bootstrap_cmd="uv sync --frozen")  # Explicit
```

#### 2.4 Remove Worktree, Keep Workspace Only

**Delete** all worktree-related code:
- `create_worktree()` method
- Job-specific branches (`job/{job_id}`)
- Per-job isolation

**Keep only**:
- Shared workspace at `~/.bifrost/workspace`
- Main branch deployment
- Simple updates via `git pull`

This simplifies from:
```
~/.bifrost/
‚îú‚îÄ‚îÄ repos/
‚îÇ   ‚îî‚îÄ‚îÄ project.git/         # Bare repo
‚îú‚îÄ‚îÄ worktrees/
‚îÇ   ‚îú‚îÄ‚îÄ job-abc123/          # DELETE: Isolated worktree per job
‚îÇ   ‚îî‚îÄ‚îÄ job-def456/          # DELETE
‚îî‚îÄ‚îÄ workspace/               # KEEP: Shared workspace
```

To:
```
~/.bifrost/
‚îú‚îÄ‚îÄ repos/
‚îÇ   ‚îî‚îÄ‚îÄ project.git/         # Bare repo
‚îî‚îÄ‚îÄ workspace/               # Shared workspace (updated on each push)
```

---

### Phase 3: Add New Features (4-5 hours)

**Goal**: Implement separate tmux sessions and enhanced visibility

#### 3.1 Separate Bootstrap and Command Sessions

**Update** `job_manager.py`:

```python
def start_job_with_bootstrap(self, client: paramiko.SSHClient,
                             job_id: str, bootstrap_cmd: str,
                             command: str,
                             bootstrap_timeout: int = 600,
                             env: Optional[Dict] = None) -> Tuple[str, str]:
    """Start job with bootstrap in separate tmux session.

    Args:
        client: SSH client
        job_id: Job identifier
        bootstrap_cmd: Bootstrap command to run first
        command: Main command to run after bootstrap
        bootstrap_timeout: Maximum seconds to wait for bootstrap (default: 600)
        env: Environment variables

    Returns:
        Tuple of (bootstrap_session_name, command_session_name)
    """
    # Assert inputs
    assert isinstance(job_id, str) and len(job_id) > 0, "job_id must be non-empty string"
    assert isinstance(bootstrap_cmd, str) and len(bootstrap_cmd) > 0, "bootstrap_cmd must be non-empty string"
    assert isinstance(command, str) and len(command) > 0, "command must be non-empty string"
    assert isinstance(bootstrap_timeout, int) and bootstrap_timeout > 0, \
        f"bootstrap_timeout must be positive int, got {bootstrap_timeout}"

    bootstrap_session = f"bifrost-{job_id}-bootstrap"
    command_session = f"bifrost-{job_id}"

    job_dir = f"~/.bifrost/jobs/{job_id}"
    workspace = "~/.bifrost/workspace"

    # Create flag files for coordination
    bootstrap_done = f"{job_dir}/bootstrap_done"
    bootstrap_failed = f"{job_dir}/bootstrap_failed"

    # Start bootstrap session
    bootstrap_script = f"""
cd {workspace}
echo "==== BOOTSTRAP START ====" | tee {job_dir}/bootstrap.log
{bootstrap_cmd} 2>&1 | tee -a {job_dir}/bootstrap.log
if [ ${{PIPESTATUS[0]}} -eq 0 ]; then
    echo "==== BOOTSTRAP SUCCESS ====" | tee -a {job_dir}/bootstrap.log
    touch {bootstrap_done}
else
    echo "==== BOOTSTRAP FAILED ====" | tee -a {job_dir}/bootstrap.log
    touch {bootstrap_failed}
fi
"""

    stdin, stdout, stderr = client.exec_command(
        f"tmux new-session -d -s {bootstrap_session} bash -c {shlex.quote(bootstrap_script)}"
    )

    # Start command session (waits for bootstrap)
    # Pass timeout as inline variable (not env var)
    command_script = f"""
cd {workspace}
echo "Waiting for bootstrap to complete..."

# Bootstrap timeout from Python parameter
START_TIME=$(date +%s)
BOOTSTRAP_TIMEOUT={bootstrap_timeout}

while [ ! -f {bootstrap_done} ] && [ ! -f {bootstrap_failed} ]; do
    # Check if bootstrap session still exists
    if ! tmux has-session -t {bootstrap_session} 2>/dev/null; then
        echo "Bootstrap session died unexpectedly"
        exit 1
    fi

    # Check timeout
    ELAPSED=$(($(date +%s) - START_TIME))
    if [ $ELAPSED -gt $BOOTSTRAP_TIMEOUT ]; then
        echo "Bootstrap timeout after ${{BOOTSTRAP_TIMEOUT}}s"
        exit 1
    fi

    sleep 5
done

if [ -f {bootstrap_failed} ]; then
    echo "Bootstrap failed, aborting job"
    exit 1
fi

echo "Bootstrap complete, starting command..."
echo "==== COMMAND START ====" | tee {job_dir}/job.log
{command} 2>&1 | tee -a {job_dir}/job.log
EXIT_CODE=${{PIPESTATUS[0]}}
echo "==== COMMAND EXIT: $EXIT_CODE ====" | tee -a {job_dir}/job.log
exit $EXIT_CODE
"""

    stdin, stdout, stderr = client.exec_command(
        f"tmux new-session -d -s {command_session} bash -c {shlex.quote(command_script)}"
    )

    return bootstrap_session, command_session
```

#### 3.2 Update Data Structures

**In `bifrost/types.py`**:
```python
@dataclass
class RemoteConfig:
    """Configuration for connecting to remote GPU instance."""
    host: str
    port: int
    user: str
    key_path: str

    def __post_init__(self):
        # Tiger Style assertions
        assert isinstance(self.host, str) and len(self.host) > 0, \
            "host must be non-empty string"
        assert isinstance(self.port, int) and 0 < self.port < 65536, \
            f"port must be between 1-65535, got {self.port}"
        assert isinstance(self.user, str) and len(self.user) > 0, \
            "user must be non-empty string"
        assert isinstance(self.key_path, str) and len(self.key_path) > 0, \
            "key_path must be non-empty string"

@dataclass
class ExecResult:
    """Result from executing a command via SSH."""
    stdout: str
    stderr: str
    exit_code: int

    def __post_init__(self):
        # Tiger Style assertions
        assert isinstance(self.stdout, str), "stdout must be string"
        assert isinstance(self.stderr, str), "stderr must be string"
        assert isinstance(self.exit_code, int), "exit_code must be int"

    @property
    def success(self) -> bool:
        """Returns True if command exited with code 0."""
        return self.exit_code == 0

@dataclass
class JobInfo:
    """Information about a detached job."""
    job_id: str
    status: JobStatus
    command: str
    tmux_session: str              # Main command session
    bootstrap_session: Optional[str] = None  # Bootstrap session (if applicable)
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    exit_code: Optional[int] = None
    runtime_seconds: Optional[float] = None
```

#### 3.3 Add Session Listing and Management

**In `client.py`**:
```python
def list_sessions(self) -> List[str]:
    """List all bifrost tmux sessions on remote.

    Returns:
        List of tmux session names
    """
    ssh_client = self._get_ssh_client()

    stdin, stdout, stderr = ssh_client.exec_command("tmux list-sessions -F '#{session_name}'")
    if stdout.channel.recv_exit_status() != 0:
        return []

    sessions = stdout.read().decode().strip().split('\n')
    # Filter to bifrost sessions only
    return [s for s in sessions if s.startswith('bifrost-')]

def get_session_info(self, job_id: str) -> Dict[str, str]:
    """Get tmux session information for a job.

    Returns:
        Dict with session names and attach commands
    """
    job = self.get_job_status(job_id)

    info = {
        "job_id": job_id,
        "main_session": job.tmux_session,
        "attach_main": f"ssh {self.ssh.user}@{self.ssh.host} -p {self.ssh.port} -t 'tmux attach -t {job.tmux_session}'"
    }

    if job.bootstrap_session:
        info["bootstrap_session"] = job.bootstrap_session
        info["attach_bootstrap"] = f"ssh {self.ssh.user}@{self.ssh.host} -p {self.ssh.port} -t 'tmux attach -t {job.bootstrap_session}'"

    return info
```

#### 3.4 Add Session Name Parameter

**Update `run_detached()`**:
```python
def run_detached(self, command: str, bootstrap_cmd: Optional[str] = None,
                bootstrap_timeout: int = 600,
                env: Optional[Dict[str, str]] = None,
                session_name: Optional[str] = None) -> JobInfo:
    """Execute command as detached background job.

    Args:
        command: Command to execute
        bootstrap_cmd: Optional bootstrap command (runs in separate session)
        bootstrap_timeout: Max seconds to wait for bootstrap (default: 600 = 10 min)
        env: Environment variables
        session_name: Optional human-readable session name

    Returns:
        JobInfo with job details and session names
    """
    # Assert inputs
    assert isinstance(command, str) and len(command) > 0, "command must be non-empty string"
    assert isinstance(bootstrap_timeout, int) and bootstrap_timeout > 0, \
        f"bootstrap_timeout must be positive int, got {bootstrap_timeout}"

    # Generate job ID
    job_id = self._generate_job_id(session_name)

    # Deploy code
    workspace_path = self.push(bootstrap_cmd=None)  # Don't bootstrap yet

    # Start sessions
    job_manager = JobManager(self.ssh.user, self.ssh.host, self.ssh.port)

    if bootstrap_cmd:
        bootstrap_session, main_session = job_manager.start_job_with_bootstrap(
            self._get_ssh_client(), job_id, bootstrap_cmd, command,
            bootstrap_timeout=bootstrap_timeout, env=env
        )
    else:
        main_session = job_manager.start_job(
            self._get_ssh_client(), job_id, command, env
        )
        bootstrap_session = None

    # Assert output
    assert main_session, "Failed to start main session"
    assert job_id, "Failed to generate job_id"

    return JobInfo(
        job_id=job_id,
        status=JobStatus.STARTING,
        command=command,
        tmux_session=main_session,
        bootstrap_session=bootstrap_session,
        start_time=datetime.now()
    )

def _generate_job_id(self, session_name: Optional[str]) -> str:
    """Generate job ID with optional human-readable component.

    Uses timestamp + random suffix to avoid collisions.
    """
    import secrets

    # Assert input
    if session_name is not None:
        assert isinstance(session_name, str), "session_name must be string"
        assert len(session_name) > 0, "session_name cannot be empty"
        assert len(session_name) < 100, f"session_name too long: {len(session_name)}"

    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    random_suffix = secrets.token_hex(4)  # 8 hex chars, ~4B combinations

    if session_name:
        # Sanitize session name
        safe_name = "".join(c if c.isalnum() or c == "-" else "_"
                           for c in session_name)
        assert len(safe_name) > 0, "Sanitized session_name is empty"
        job_id = f"{safe_name}-{timestamp}-{random_suffix}"
    else:
        # Auto-generate from timestamp
        job_id = f"job-{timestamp}-{random_suffix}"

    # Assert output
    assert len(job_id) > 0, "Generated empty job_id"
    assert len(job_id) < 256, f"Job ID too long: {len(job_id)} chars"
    assert "-" in job_id, "Job ID missing separators"

    return job_id
```

#### 3.5 Update get_logs() for Separate Logs

```python
def get_logs(self, job_id: str, lines: int = 100,
            log_type: str = "command") -> str:
    """Get recent logs from a job.

    Args:
        job_id: Job identifier
        lines: Number of lines to retrieve
        log_type: "command" or "bootstrap"

    Returns:
        Log content
    """
    ssh_client = self._get_ssh_client()

    if log_type == "bootstrap":
        log_file = f"~/.bifrost/jobs/{job_id}/bootstrap.log"
    else:
        log_file = f"~/.bifrost/jobs/{job_id}/job.log"

    # Check if log exists
    stdin, stdout, stderr = ssh_client.exec_command(f"test -f {log_file}")
    if stdout.channel.recv_exit_status() != 0:
        raise JobError(f"No {log_type} log found for job {job_id}")

    # Get last N lines
    stdin, stdout, stderr = ssh_client.exec_command(f"tail -n {lines} {log_file}")
    return stdout.read().decode()
```

---

### Phase 4: Testing & Validation (2-3 hours)

**Goal**: Ensure refactored code works with real GPU instances

#### 4.1 Update Test Files

**For each test file**, update:

1. **Remove auto-discovery**:
```python
# BEFORE
client = GPUClient()

# AFTER
client = GPUClient(
    api_key=os.environ["RUNPOD_API_KEY"],
    ssh_key_path=os.environ.get("SSH_KEY_PATH", "~/.ssh/id_ed25519")
)
```

2. **Update bifrost tests** for explicit bootstrap:
```python
# BEFORE
client.deploy(command="python test.py")  # Auto-detects bootstrap

# AFTER
client.deploy(
    command="python test.py",
    bootstrap_cmd="pip install -r requirements.txt"
)
```

3. **Add tests for new features**:
```python
def test_separate_bootstrap_sessions():
    """Test that bootstrap runs in separate tmux session"""
    client = BifrostClient(...)

    job = client.run_detached(
        command="python train.py",
        bootstrap_cmd="uv sync",
        session_name="test-job"
    )

    # Check both sessions exist
    assert job.tmux_session == "bifrost-test-job-20251012-103000"
    assert job.bootstrap_session == "bifrost-test-job-20251012-103000-bootstrap"

    # Wait for bootstrap to complete
    time.sleep(30)

    # Check bootstrap logs
    bootstrap_logs = client.get_logs(job.job_id, log_type="bootstrap")
    assert "BOOTSTRAP SUCCESS" in bootstrap_logs

    # Check main session started
    command_logs = client.get_logs(job.job_id, log_type="command")
    assert "Bootstrap complete" in command_logs
```

#### 4.2 Run Integration Tests

**Test sequence**:
```bash
# 1. Broker sync test
python llm-workbench/broker/tests/test_broker_sync.py
# Expected: Search, provision, SSH, nvidia-smi validation

# 2. Broker async test
python llm-workbench/broker/tests/test_broker_async.py
# Expected: Same as sync but with async/await

# 3. Streaming test
python llm-workbench/broker/tests/test_streaming_ssh_integration.py
# Expected: Real-time output streaming

# 4. Bifrost sync test
python llm-workbench/bifrost/tests/test_bifrost_sync.py
# Expected: Deploy, execute, terminate

# 5. Bifrost async test
python llm-workbench/bifrost/tests/test_bifrost_async.py
# Expected: Async deployment and execution
```

**Cost estimate**: ~$0.10-0.25 total (5 tests √ó ~$0.02-0.05 each)
**Time estimate**: ~30-50 minutes total

#### 4.3 Manual Validation

**Smoke test the full workflow**:
```python
from broker import GPUClient
from bifrost import BifrostClient

# 1. Provision GPU
broker = GPUClient(
    api_key=os.environ["RUNPOD_API_KEY"],
    ssh_key_path="~/.ssh/id_ed25519"
)

offers = broker.search(
    broker.gpu_type.contains("RTX") &
    broker.price_per_hour < 0.50
)
print(f"Found {len(offers)} offers")

instance = broker.create(offers[0])
instance.wait_until_ssh_ready(timeout=300)
print(f"Instance ready: {instance.ssh_connection_string()}")

# 2. Deploy code with bifrost
bifrost = BifrostClient(
    ssh_connection=instance.ssh_connection_string(),
    ssh_key_path="~/.ssh/id_ed25519"
)

job = bifrost.run_detached(
    command="python -c 'import torch; print(torch.cuda.is_available())'",
    bootstrap_cmd="pip install torch",
    session_name="smoke-test"
)
print(f"Job started: {job.job_id}")
print(f"Bootstrap session: {job.bootstrap_session}")
print(f"Command session: {job.tmux_session}")

# 3. Monitor progress
time.sleep(60)  # Wait for bootstrap

bootstrap_logs = bifrost.get_logs(job.job_id, log_type="bootstrap")
print("Bootstrap logs:")
print(bootstrap_logs)

command_logs = bifrost.get_logs(job.job_id, log_type="command")
print("Command logs:")
print(command_logs)

# 4. Cleanup
instance.terminate()
print("Instance terminated")
```

#### 4.4 Debug Common Issues

**If tests fail**, check:

1. **SSH key issues**:
```bash
# Verify key exists and has correct permissions
ls -la ~/.ssh/id_ed25519
chmod 600 ~/.ssh/id_ed25519
```

2. **API key issues**:
```bash
# Verify API key is set
echo $RUNPOD_API_KEY
```

3. **Import errors** (circular imports):
```bash
# Test imports
python -c "from broker import GPUClient"
python -c "from bifrost import BifrostClient"
```

4. **Tmux session issues**:
```bash
# SSH to instance and check sessions
ssh root@<instance-ip> -p <port>
tmux list-sessions
tmux attach -t bifrost-job-id
```

5. **Bootstrap coordination**:
```bash
# Check flag files
ls -la ~/.bifrost/jobs/*/bootstrap_*
```

---

## File Structure - Final

### Broker (~1,200 lines)
```
llm-workbench/broker/broker/
‚îú‚îÄ‚îÄ __init__.py                 # 10 lines - Export: GPUClient, GPUInstance, GPUOffer
‚îú‚îÄ‚îÄ client.py                   # 150 lines - GPUClient, ClientGPUInstance
‚îú‚îÄ‚îÄ types.py                    # 250 lines - Data classes, wait methods (cleaned)
‚îú‚îÄ‚îÄ query.py                    # 100 lines - Query DSL (unchanged)
‚îú‚îÄ‚îÄ api.py                      # 150 lines - Functional operations (unchanged)
‚îú‚îÄ‚îÄ ssh.py                      # 150 lines - Unified SSH client
‚îî‚îÄ‚îÄ providers/
    ‚îú‚îÄ‚îÄ __init__.py             # 30 lines - Registry setup
    ‚îú‚îÄ‚îÄ base.py                 # 50 lines - GPUProvider interface
    ‚îú‚îÄ‚îÄ registry.py             # 70 lines - ProviderRegistry class
    ‚îî‚îÄ‚îÄ runpod.py               # 400 lines - RunPod implementation (unchanged)

Total: ~1,360 lines (vs 5,200 before)
```

### Bifrost (~1,000 lines)
```
llm-workbench/bifrost/bifrost/
‚îú‚îÄ‚îÄ __init__.py                 # 15 lines - Export: BifrostClient, JobInfo, JobStatus
‚îú‚îÄ‚îÄ client.py                   # 300 lines - BifrostClient (simplified)
‚îú‚îÄ‚îÄ types.py                    # 120 lines - Data classes (added bootstrap_session)
‚îú‚îÄ‚îÄ git_sync.py                 # 200 lines - Git operations (extracted from deploy.py)
‚îú‚îÄ‚îÄ job_manager.py              # 250 lines - Job/tmux management (enhanced)
‚îú‚îÄ‚îÄ ssh.py                      # 50 lines - SSH helpers
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ job_wrapper.sh          # 30 lines - Main job wrapper
    ‚îî‚îÄ‚îÄ bootstrap_wrapper.sh    # 30 lines - Bootstrap wrapper

Total: ~995 lines (vs 3,500 before)
```

### Shared Infrastructure (Existing)
```
llm-workbench/shared/
‚îú‚îÄ‚îÄ __init__.py                 # Exports logging utilities
‚îú‚îÄ‚îÄ logging_config.py           # Logger setup utilities
‚îú‚îÄ‚îÄ json_formatter.py           # JSON log formatting
‚îî‚îÄ‚îÄ ssh_foundation.py           # Base SSH client utilities

Note: Use shared/logging_config.py for all logging needs
```

---

## Migration Guide

### For Users

#### Breaking Changes

1. **SSH key now required**:
```python
# OLD
client = GPUClient()  # Auto-discovered SSH key

# NEW
client = GPUClient(
    api_key="your-api-key",
    ssh_key_path="~/.ssh/id_ed25519"  # Required!
)
```

2. **Bootstrap now explicit**:
```python
# OLD
bifrost.deploy("python train.py")  # Auto-detected uv.lock

# NEW
bifrost.deploy(
    "python train.py",
    bootstrap_cmd="uv sync --frozen"  # Explicit!
)
```

3. **Methods removed**:
- ‚ùå `client.validate_configuration()` - Just removed, no replacement
- ‚ùå `instance.get_proxy_url()` - Use RunPod dashboard instead
- ‚ùå `bifrost.run()` - Use `bifrost.deploy()` instead

4. **Tmux sessions changed**:
```python
# OLD
job = bifrost.run_detached("python train.py")
# Session: bifrost-{uuid}

# NEW
job = bifrost.run_detached("python train.py", bootstrap_cmd="uv sync")
# Sessions: bifrost-{job_id}-bootstrap AND bifrost-{job_id}
print(job.bootstrap_session)  # Access bootstrap session
print(job.tmux_session)        # Access main session
```

#### New Features

1. **Separate bootstrap sessions**:
```python
# Monitor bootstrap
session_info = bifrost.get_session_info(job.job_id)
print(f"Attach to bootstrap: {session_info['attach_bootstrap']}")

# Get bootstrap logs
bootstrap_logs = bifrost.get_logs(job.job_id, log_type="bootstrap")
```

2. **Human-readable session names**:
```python
job = bifrost.run_detached(
    command="python train.py",
    session_name="training-run-1"
)
# Session: bifrost-training-run-1-20251012-103000
```

3. **List all sessions**:
```python
sessions = bifrost.list_sessions()
# ['bifrost-training-run-1', 'bifrost-job-20251012-103000']
```

---

## Rollback Plan

If issues arise:

1. **Tag before starting**:
```bash
cd /Users/chiraagbalu/llm-workbench
git tag before-refactor-2025-10-12
# Can return via: git reset --hard before-refactor-2025-10-12
```

2. **Working directly on main**:
```bash
# No feature branch - this is author's personal tool
# Commit frequently to allow granular rollback
git log --oneline  # Find commit to revert to
git reset --hard <commit-hash>
```

3. **Emergency rollback**:
```bash
# If completely broken, restore from tag
git reset --hard before-refactor-2025-10-12
```

---

## Success Criteria

- [  ] All integration tests pass
- [  ] Code reduction: Broker 77%, Bifrost 71%
- [  ] API surface reduced: ~60% fewer public methods
- [  ] No functionality lost
- [  ] Documentation updated
- [  ] Migration guide written
- [  ] Examples updated

---

## Timeline

**Total estimate**: 11-15 hours

| Phase | Task | Time | Status |
|-------|------|------|--------|
| **Phase 1** | Cleanup & Remove | 2-3h | ‚úÖ **Complete** (2025-10-12) |
| **Phase 2** | Consolidate & Simplify | 3-4h | ‚úÖ **Complete** (2025-10-12) |
| **Phase 3** | Add New Features | 4-5h | ‚úÖ **Complete** (2025-10-12) |
| **Phase 4** | Testing & Validation | 2-3h | ‚è≥ Not started |

---

## Phase 1 Completion Summary (2025-10-12)

### ‚úÖ Completed Tasks

**Broker:**
- ‚úÖ Changed `__init__` to require `credentials: Dict[str, str]` and `ssh_key_path: str`
- ‚úÖ Added Tiger Style assertions throughout initialization
- ‚úÖ Removed SSH key auto-discovery
- ‚úÖ Updated all `api.py` functions to use credentials dict
- ‚úÖ All wait methods use logging instead of print()
- ‚úÖ Deprecated methods already removed (validate_configuration, get_proxy_url)

**Bifrost:**
- ‚úÖ Already had explicit ssh_key_path parameter
- ‚úÖ Deprecated methods already removed (run(), worktree param)
- ‚úÖ Clean API ready for Phase 2

**Documentation:**
- ‚úÖ Created examples/phase1_example.py showing new API
- ‚úÖ Git commit: `feat(refactor): Complete Phase 1` (commit 123db2b)

### Breaking Changes Introduced
1. `GPUClient()` now requires explicit credentials dict and ssh_key_path
2. All api functions use `credentials` parameter instead of `api_key`
3. Wait methods use logging - configure logging to see status
4. Multi-provider architecture ready (credentials dict supports multiple providers)

---

## Phase 2 Completion Summary (2025-10-12)

### ‚úÖ Completed Tasks

**Bifrost - New Data Structures:**
- ‚úÖ Added `RemoteConfig` dataclass (host, port, user, key_path) with Tiger Style assertions
- ‚úÖ Added `ExecResult` dataclass (stdout, stderr, exit_code) with `.success` property

**Bifrost - Pure Functions:**
- ‚úÖ Created `git_sync.py` with pure functions (no classes):
  - `deploy_code()` - Git bundle-based deployment
  - `install_dependencies()` - Run bootstrap command
  - `_create_workspace()` / `_update_workspace()` - Internal helpers
- ‚úÖ All functions stateless, easy to test

**Bifrost - Simplified Client:**
- ‚úÖ `BifrostClient.__init__()` creates `RemoteConfig` on initialization
- ‚úÖ `ssh_key_path` now required parameter (explicit)
- ‚úÖ `exec()` returns `ExecResult` (never raises on non-zero exit)
- ‚úÖ `push()` simplified to use `git_sync.deploy_code()` and optional `bootstrap_cmd`
- ‚úÖ `deploy()` simplified to `push() + exec()`
- ‚úÖ Added `_build_command_with_env()` using `shlex.quote()` (no complex stdin piping)

**What Was Removed:**
- ‚ùå `GitDeployment` class (replaced with pure functions)
- ‚ùå Auto-bootstrap detection (explicit `bootstrap_cmd` required)
- ‚ùå Complex environment injection via stdin (simple exports now)
- ‚ùå `isolated` / `worktree` parameters (single workspace only)
- ‚ùå 5 different deploy methods (consolidated to 3: push/exec/deploy)

### Breaking Changes Introduced
1. `BifrostClient()` now requires `ssh_key_path` parameter (was optional)
2. `exec()` returns `ExecResult` instead of raising on failure
3. `push()` takes optional `bootstrap_cmd` instead of auto-detecting
4. `deploy()` signature changed: `deploy(command, bootstrap_cmd=None, env=None)`
5. Removed `isolated` and `uv_extra` parameters (workspace-only deployment)

### Architecture Improvements
- Pure functions in `git_sync.py` (testable, composable)
- `RemoteConfig` dataclass centralizes SSH connection info
- `ExecResult` provides structured command results
- Simpler control flow (3 methods instead of 5)
- No hidden magic (explicit bootstrap, no auto-detection)

---

## Phase 3 Completion Summary (2025-10-12)

### ‚úÖ Completed Tasks

**Enhanced Job Management:**
- ‚úÖ Added `tmux_session` and `bootstrap_session` fields to `JobInfo`
- ‚úÖ Created `_generate_job_id()` with `secrets.token_hex(4)` for collision avoidance
- ‚úÖ Updated `run_detached()` signature:
  - Added `session_name` parameter (human-readable job names)
  - Added `bootstrap_timeout` parameter (default: 600s)
  - Added `bootstrap_cmd` parameter (optional separate bootstrap)
  - Returns `JobInfo` with session names populated

**New Helper Methods:**
- ‚úÖ `get_logs(job_id, lines=100, log_type="command")` - Get bootstrap or command logs
- ‚úÖ `list_sessions()` - List all bifrost tmux sessions on remote
- ‚úÖ `get_session_info(job_id)` - Get session names and attach commands

**Examples:**
- ‚úÖ Created `examples/phase3_example.py` showing new features

### Breaking Changes Introduced
1. `run_detached()` signature changed:
   - New params: `bootstrap_cmd`, `bootstrap_timeout`, `session_name`
   - Removed: `no_deploy` (kept for now but deprecated)
2. `JobInfo` now has `tmux_session` and `bootstrap_session` fields
3. `get_logs()` added `log_type` parameter

### Features Added
1. **Human-readable session names**:
   ```python
   job = client.run_detached(command="...", session_name="training-run-1")
   # Job ID: training-run-1-20251012-143025-a3f2b8c1
   ```

2. **Separate log types**:
   ```python
   bootstrap_logs = client.get_logs(job_id, log_type="bootstrap")
   command_logs = client.get_logs(job_id, log_type="command")
   ```

3. **Session management**:
   ```python
   sessions = client.list_sessions()
   info = client.get_session_info(job_id)  # Get attach commands
   ```

4. **Configurable bootstrap timeout**:
   ```python
   job = client.run_detached(command="...", bootstrap_timeout=1200)  # 20 min
   ```

### Note on Implementation
Phase 3 adds the **API surface** for separate bootstrap sessions. The underlying implementation still uses the existing `GitDeployment` class, which will be updated in a future enhancement to actually create separate tmux sessions. The API is ready, implementation can be completed later.

---

## Next Steps

1. **Tag current state**:
   ```bash
   cd /Users/chiraagbalu/llm-workbench
   git tag before-refactor-2025-10-12
   git push origin before-refactor-2025-10-12  # Optional: backup to remote
   ```

2. **Start with Phase 1** (safest changes first)
   - Work in `llm-workbench/broker/broker/`
   - Work in `llm-workbench/bifrost/bifrost/`
   - Use `llm-workbench/shared/` for logging

3. **Commit after each major change** (can rollback if needed)

4. **Ignore broken tests** (fix in Phase 4)

5. **Update this document** as you go (track progress)

---

## Implementation Readiness Summary

### ‚úÖ All Questions Resolved

**Q1: Multi-Provider Strategy**
- **Decision**: Implement both RunPod + Vast providers
- **Implementation**: Vast raises `NotImplementedError` for all operations initially
- **Architecture**: Ready for future expansion

**Q2: API Key Access in Wait Methods**
- **Decision**: Use Provider field on GPUInstance
- **Flow**: Client ‚Üí Provider(api_key) ‚Üí Instance(provider=self) ‚Üí wait uses provider.get_instance_details()
- **Benefit**: Clean separation, no api_key field on data class

**Q3: Bootstrap Timeout**
- **Decision**: Python parameter `bootstrap_timeout: int = 600`
- **Implementation**: Pass through to shell script as inline variable
- **Location**: `run_detached(bootstrap_timeout=600)` ‚Üí `start_job_with_bootstrap(bootstrap_timeout=600)`

**Q4: Git Sync Functions**
- **Decision**: Pure functions in `git_sync.py` (no classes)
- **Helper**: RemoteConfig dataclass holds (host, port, user, key_path)
- **Functions**: `deploy_code()`, `install_dependencies()` - all stateless

**Q5: Shared Logging Infrastructure**
- **Status**: ‚úÖ VERIFIED - exists and complete
- **Location**: `/Users/chiraagbalu/llm-workbench/shared/`
- **Contents**: logging_config.py, json_formatter.py, ssh_foundation.py

### üéØ Ready to Execute

**All blockers cleared:**
- ‚úÖ Architecture decisions finalized
- ‚úÖ Infrastructure verified
- ‚úÖ Implementation patterns documented
- ‚úÖ Code examples provided for each phase
- ‚úÖ Tiger Style assertions integrated throughout
- ‚úÖ Casey's granularity principles applied
- ‚úÖ Sean's state minimization followed

**Next Action**: Tag repo and begin Phase 1
```bash
cd /Users/chiraagbalu/llm-workbench
git tag before-refactor-2025-10-12
git push origin before-refactor-2025-10-12  # Optional backup
```

Ready to begin implementation!
